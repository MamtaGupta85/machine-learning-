# -*- coding: utf-8 -*-
"""payment_fraud.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vCwG9xJxWBhTfsMbYPOXS3Exlf18tjNo
"""

#@title import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import VotingClassifier, RandomForestClassifier
from sklearn.metrics import accuracy_score, r2_score, confusion_matrix, ConfusionMatrixDisplay, classification_report
from imblearn.over_sampling import SMOTE
from sklearn.svm import SVC
import warnings
warnings.filterwarnings('ignore')

#connecting with the drive
from google.colab import drive
drive.mount('/content/drive')

path_fraud = '/content/drive/MyDrive/Machine Learning/onlinefraud.csv'

df_fraud = pd.read_csv(path_fraud)

# The dimensions of the dataset
df_fraud.shape

# first five rows of the dataset
df_fraud.head()

#detailed information and datatype of each column
df_fraud.info()

"""EXPLORATORY DATA ANALYSIS  AND PREPROCESSING"""

#describe the data
df_fraud.describe().T

# checking for the missing values
df_fraud.isna().sum()

#since we have no null value, we will check for the value counts to see if there are any special characters
for cols in (df_fraud.columns):
  uni = df_fraud.groupby(cols)[cols].count()
  print(f'value counts for {uni}')
  print('===================')

#visualisation of the distribution of classes of target variable
plt.figure(figsize=(8,6))
sns.countplot(x='isFraud', data= df_fraud, palette='spring')
plt.title('count of values for fraud types')
plt.xlabel('isFraud')
plt.ylabel('Count')
plt.tight_layout()
plt.show()

df_fraud.drop(columns=['nameOrig','nameDest'], axis=1, inplace=True)

#classify the categorical values
cat_data = df_fraud.dtypes==object
list_cat_data = df_fraud.columns[cat_data].tolist()

list_cat_data

#classify the numerical data
num_data = df_fraud.dtypes!=object
list_num_data = df_fraud.columns[num_data].tolist()

list_num_data

#@title Univariate Analysis

plt.rcParams['figure.figsize']=(15,6)
plt.subplot(1,2,1)
ax= sns.countplot(x=df_fraud['type'], palette='winter')
for p in ax.patches:
  ax.annotate(format(p.get_height(), '.2f'), (p.get_x()+ p.get_width()/2, p.get_height()), ha='center', va='center', color='black', size=8)
plt.title('Type of payments Countplot')

plt.subplot(1,2,2)
df_fraud['type'].value_counts().plot.pie(autopct='%1.f%%', explode=[0.1,0,0,0,0])
plt.title('Payment types piechart')

plt.rcParams['figure.figsize']=(12,4)
plt.subplot(1,2,1)
sns.scatterplot(x=df_fraud['amount'], y=df_fraud['amount'].value_counts())
plt.axvline(np.mean(df_fraud['amount']), color='r')
plt.title("amount dispersion")
plt.subplot(1,2,2)
sns.boxplot(x=df_fraud['amount'])
plt.title("amount boxplot")

plt.rcParams['figure.figsize']=(12,4)
plt.subplot(1,2,1)
plt.scatter(df_fraud.index,df_fraud['isFlaggedFraud'])
plt.title("dispersion for flagged fraud")
plt.subplot(1,2,2)
sns.boxplot(x=df_fraud['isFlaggedFraud'])
plt.title("outliers for if Flagged Fraud")

#@title Multivarite Analysis
plt.figure(figsize=(12,4))
ax = sns.barplot(x=df_fraud['type'],y=df_fraud['amount'], hue=df_fraud['isFraud'], palette='autumn')
for p in ax.patches:
   ax.annotate(format(p.get_height()), (p.get_x()+p.get_width()/2, p.get_height()), ha='center', va='center', color='black', size=8)
plt.tight_layout()
plt.show()

plt.rcParams['figure.figsize']=(12,6)
sns.heatmap(df_fraud[list_num_data].corr(), annot=True, cmap='magma')
plt.show()

#Variance Inflation factor to know which features to drop
from statsmodels.stats.outliers_influence import variance_inflation_factor

vif_data = pd.DataFrame()
x = df_fraud[list_num_data]
vif_data['features'] = x.columns
vif_data['VIF']= [variance_inflation_factor(x.values,i) for i in range(len(x.columns))]

vif_data

#creating a copy of the dataset
data = df_fraud.copy()

# we will drop where there is zero corr with target variable and high VIF
df_fraud.drop(columns=['oldbalanceDest','newbalanceDest'],axis=1,inplace=True)

#encode the categorical value
le = LabelEncoder()
df_fraud['type']= le.fit_transform(df_fraud['type'])

# in the dataset since we had few values of class 1, we will use SMOTE to stabilise the data
smote = SMOTE()
X = df_fraud.drop(columns=['isFraud'], axis=1)
y= df_fraud['isFraud']
x_smote, y_smote = smote.fit_resample(X,y)

print(x_smote.shape)
print(y_smote.shape)

#re-check the values of y after SMOTE
y_smote.value_counts().plot(kind='bar', color=['yellow','green'])
plt.title('countplot for new y')
plt.show()

#splitting the data
train_x, test_x, train_y, test_y = train_test_split(x_smote,y_smote, test_size=0.2)

#scaling the training and testing data
sc = StandardScaler()
train_x = sc.fit_transform(train_x)
test_x = sc.fit_transform(test_x)

#@title training the model
lg_fraud = LogisticRegression()
lg_fraud.fit(train_x,train_y)

#predict the value of y
y_pred = lg_fraud.predict(test_x)

#checking the accuracy score of model
print(f'the accuracy score of model is {accuracy_score(test_y, y_pred)}')

#classification report
print(classification_report(test_y, y_pred))

"""Decision Tree Classification"""

rs = RobustScaler()
train_x1 = rs.fit_transform(train_x)
test_x1= rs.fit_transform(test_x)

f_dt = DecisionTreeClassifier()
f_dt.fit(train_x1,train_y)

#predicting the value of y
y_dt = f_dt.predict(test_x1)

#checking the accuracy score of model
print(f'the accuracy score of model is {accuracy_score(test_y, y_dt)}')

#classification report
print(classification_report(test_y, y_dt))

#Confusion matrix
conf_matrix = confusion_matrix(test_y, y_dt)

plt.rcParams['figure.figsize']=(10,5)
ConfusionMatrixDisplay(confusion_matrix=conf_matrix).plot()

#@title Support Vector Machine

svc_fraud = SVC(kernel='poly', gamma = 0.01, random_state=0, C=1.0)
svc_fraud.fit(train_x1, train_y)

predict_y = svc_fraud.predict(test_x1)

svc_fraud.score(test_x,test_y)

svc_fraud.score(train_x,train_y)